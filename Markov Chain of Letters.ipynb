{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Deniz Ekiz \n",
    "Number: 2016700051\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to 16.3-5 and 18\n",
    "### 16.3\n",
    "In this data set, I see a timeseries like $y = z$ where, $z$ is a and y is a function from $\\mathbb{R} \\rightarrow \\mathbb{R} $.\n",
    "There is some points where there are some noises. Let's define noise with $u$\n",
    "\n",
    "$y = z + u$\n",
    "\n",
    "The interval of $z$ is $[0,25]$. \n",
    "\n",
    "$u = random(-25,25)$ with a probaility of $p_2$\n",
    "\n",
    "$u = 0 $ with a probability of $1-p_2$\n",
    "\n",
    "$z_{t + 1} = z_{t}$ with a probability of $p_1$\n",
    "\n",
    "$z_{t + 1} = random(0,25)$ with a probability of $1-p_1$\n",
    "### 16.4\n",
    "\n",
    "\n",
    "<img src =\"./files/16.4.jpg\"/>\n",
    "### 16.5\n",
    "<img src =\"./files/16.5.jpg\"/>\n",
    "\n",
    "### 18\n",
    "#### 18.1  Draw the corresponding directed graphical model\n",
    "\n",
    "<img src=\"files/18_directed.jpg\"/>\n",
    "\n",
    "#### 18.2 Draw an equivalent factor graph and undirected graphical model\n",
    "\n",
    "##### Factor Graph\n",
    "\n",
    "<img src =\"files/factor_1.jpg\"/>\n",
    "\n",
    "##### Undirected Graphical Model\n",
    "\n",
    "<img src =\"files/18_undirected.jpg\"/>\n",
    "\n",
    "#### 18.3  If all the variables have $N$ states, compute the space to store the model specification.\n",
    "\n",
    "$P(A) \\rightarrow N-1$\n",
    "\n",
    "$P(M) \\rightarrow N-1$\n",
    "\n",
    "$P(L|M) \\rightarrow (N-1)^2$\n",
    "\n",
    "$P(T|A) \\rightarrow (N-1)^2$\n",
    "\n",
    "$P(F|T,L) \\rightarrow (N-1)^3$\n",
    "\n",
    "$P(T|A) \\rightarrow (N-1)^2$\n",
    "\n",
    "$P(B|M) \\rightarrow (N-1)^2$\n",
    "\n",
    "$P(X|F) \\rightarrow (N-1)^2$\n",
    "\n",
    "$p(D|F,B)  \\rightarrow (N-1)^3$\n",
    "\n",
    "The summation equals to $3(N-1)^3 + 5(N-1)^2 + 2(N-1) $\n",
    "\n",
    "#### 18.4  Verify the following conditional independence statements using d-separation. State if they are true or false and explain why.\n",
    "\n",
    "a) A ⊥⊥ M|∅\n",
    "\n",
    "True. Because there is no such connection between A and M given empty set.\n",
    "\n",
    "b) A ⊥⊥ M|X\n",
    "\n",
    "False, The variable F is a collider along the path A-T-F-X and M-L-F-X. Therefore, conditioning on X makes A and B depandent \n",
    "\n",
    "c) T ⊥⊥ L|X\n",
    "\n",
    "False, F is a collider in the path T-F-X and L-F-X therefore, they are depandent.\n",
    "\n",
    "d) X ⊥⊥ L|F\n",
    "\n",
    "True, F is a collider on the oath L-F-X conditionin on F makes them independant\n",
    "\n",
    "e) X ⊥⊥ L|D\n",
    "\n",
    "False, D is not in the path of L-F-X. They are dependant.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr?gr?mm?ng?H?m?w?rk 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', '0.0002835')\n",
      "('b', '0.0228302')\n",
      "('c', '0.0369041')\n",
      "('d', '0.0426290')\n",
      "('e', '0.0012216')\n",
      "('f', '0.0075739')\n",
      "('g', '0.0171385')\n",
      "('h', '0.0014659')\n",
      "('i', '0.0372661')\n",
      "('j', '0.0002353')\n",
      "('k', '0.0110124')\n",
      "('l', '0.0778259')\n",
      "('m', '0.0260757')\n",
      "('n', '0.2145354')\n",
      "('o', '0.0005459')\n",
      "('p', '0.0195213')\n",
      "('q', '0.0001749')\n",
      "('r', '0.1104770')\n",
      "('s', '0.0934290')\n",
      "('t', '0.1317960')\n",
      "('u', '0.0098029')\n",
      "('v', '0.0306574')\n",
      "('w', '0.0088799')\n",
      "('x', '0.0009562')\n",
      "('y', '0.0233701')\n",
      "('z', '0.0018701')\n",
      "('.', '0.0715219')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "t = 0.0\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#given N\n",
    "#create CDF\n",
    "sn = 10\n",
    "selection = 26 #string index in alphabet\n",
    "def string_generator(selection,sn):\n",
    "    N = 27\n",
    "    selected_strings = np.zeros([0,1])\n",
    "    for z in range(0,sn):\n",
    "        CDF = np.zeros((0,2))\n",
    "        my_sum = 0.0\n",
    "        prev_let = alphabet[selection]\n",
    "        for i in range(0,N):\n",
    "            #my_str = \"$p(x_t = \\text{'\" + alphabet[i]+ \"'} | x_{t-1} = \\text{'.'}$ ) = \"+ T[i][letter2idx[prev_let]] \n",
    "            #display( Latex(r\"$p(x_t = \\text{'\" + alphabet[i]+ r\"'} | x_{t-1} = \\text{'\"+prev_let+r\"'}$ ) = \"+ T[i][letter2idx[prev_let]] ))\n",
    "            CDF = np.vstack((CDF,[alphabet[i],float(T[i][letter2idx[prev_let]]) ]))\n",
    "            my_sum += float(T[i][letter2idx[prev_let]])\n",
    "        #print(my_sum)\n",
    "        # normalize and find CDF\n",
    "        CDF[0,1] = float(CDF[0,1])/my_sum\n",
    "        for i in range(1,N):\n",
    "            if(len(CDF[:,1])>1):\n",
    "                CDF[i,1] =  float(CDF[i,1])/my_sum  + float(CDF[i-1,1])\n",
    "            else:\n",
    "                CDF[0,1] = 1\n",
    "\n",
    "\n",
    "        #print(CDF)\n",
    "        s = np.random.uniform(0,1,1)\n",
    "        for i in range(0,len(s)):\n",
    "            for j in range(0,len(CDF[:,1])):\n",
    "                if(s[i] <= float(CDF[j,1])):\n",
    "                    selected_strings = np.vstack((selected_strings,CDF[j,0]))\n",
    "                    selection = j\n",
    "                    break\n",
    "    #print(\"For N= \"+ str(N) +\" and Sample number= \"+ str(sn) +\" Selected strings:\")\n",
    "    return selected_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d a z a v a h t x e\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "gens = string_generator(letter2idx['.'],N)\n",
    "for i in range(0,len(gens)):\n",
    "    print(str(gens[i,0])),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "t k c i  \n",
      "t n a c  \n",
      "t p p x  \n",
      "t a v x  \n",
      "t i x x  \n",
      "t . y p  \n",
      "t i l a  \n",
      "t i h g  \n",
      "t a x x  \n",
      "t s i .\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(\" \")\n",
    "    gens = string_generator(letter2idx['t'],3)\n",
    "    print('t'),\n",
    "    for i in range(0,len(gens)):\n",
    "        print(str(gens[i,0])),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the.bre.n.f.x.', 'tursthen..tonbe.tnswhre.', 'in.ath.tanhen..te.reing', 'quret.thez.the.tt.th.the.th.']\n"
     ]
    }
   ],
   "source": [
    "def find_empty_chars(st):\n",
    "    i = 0\n",
    "    z = 0\n",
    "    my_index = []\n",
    "    for c in st:\n",
    "        if(c == '_'):\n",
    "            my_index.append(z)\n",
    "            i = i + 1\n",
    "        z = z + 1\n",
    "    return my_index\n",
    "\n",
    "for j in range(0,len(test_strings)):\n",
    "    a = find_empty_chars(test_strings[j])\n",
    "    #print(a)\n",
    "    for i in a:\n",
    "        my_str = list(test_strings[j])\n",
    "        if i == 0:\n",
    "            #print(i)\n",
    "            my_str[i] = alphabet[np.argmax(T[letter2idx['.']])]\n",
    "        else:\n",
    "            my_str[i] = alphabet[np.argmax(T[letter2idx[my_str[i-1]]])]\n",
    "        test_strings[j] = \"\".join(my_str)\n",
    "print(test_strings)       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of most likely hood approach, we can use random string generation model that we used in Part 3. I think it should be more natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
