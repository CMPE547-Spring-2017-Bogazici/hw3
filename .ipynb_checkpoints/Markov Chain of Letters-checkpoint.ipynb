{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Mehmetcan Tütüncü\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution to 16.3\n",
    "\n",
    "\n",
    "$S_{t+1} = \\begin{cases} \n",
    "      S_t & with \\: p \\\\\n",
    "      U(0,30) & with \\: 1-p \n",
    "   \\end{cases}\n",
    "$\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$y_{t} = \\begin{cases} \n",
    "      S_t & with \\: q \\\\\n",
    "      U(0,30) & with \\: 1-q \n",
    "   \\end{cases}\n",
    "$\n",
    "\n",
    "<img src=\"files/fig16-3.jpg\"= 100x20 style=\"width: 500px;\">\n",
    "#### Solution to 16.4\n",
    "\n",
    "\n",
    "It can be modeled as a Markov(1) model with the following transition matrix below, for a b c d e states:\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "    1-{p_1} & p_1 &  &  &  \\\\\n",
    "    p_2 &  & 1-p_2 &  & \\\\\n",
    "    1-p_3 & & & p_3 & \\\\\n",
    "    &&&& 1\\\\\n",
    "    1-p_4 &&&& p_4\n",
    "  \\end{bmatrix}\n",
    " $$\n",
    "#### Solution to 16.5\n",
    "\n",
    "\n",
    "$x_{t+1} = \\begin{cases} \n",
    "      x_t & with \\: p \\\\\n",
    "      1-x_t & with \\: 1-p \n",
    "   \\end{cases}\n",
    "$\n",
    "\n",
    "\n",
    "#### Solution to 18\n",
    "\n",
    "1)\n",
    "\n",
    "\n",
    "<img src=\"files/fig18-1.jpg\"= 100x20 style=\"width: 400px;\">\n",
    "\n",
    "\n",
    "2)\n",
    "\n",
    "<img src=\"files/fig18-2.jpg\"= 100x20 style=\"width: 400px;\">\n",
    "\n",
    "\n",
    "<img src=\"files/fig18-3.jpg\"= 100x20 style=\"width: 400px;\">\n",
    "\n",
    "3)\n",
    "For $P(F | T,L)$ we need $(N-1) * N^2$ parameters. Similarly, total number of parameters is\n",
    "$$ N^2(N-1)+ (N-1) + N(N-1) + N(N-1) + N(N-1) + N(N-1) + N^2(N-1) + (N-1) = 2*(N+1)^2(N-1) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Homework 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'t'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', '0.0393295')\n",
      "('b', '0.0001590')\n",
      "('c', '0.0037195')\n",
      "('d', '0.0000674')\n",
      "('e', '0.0892434')\n",
      "('f', '0.0009218')\n",
      "('g', '0.0000404')\n",
      "('h', '0.3352928')\n",
      "('i', '0.0666758')\n",
      "('j', '0.0000054')\n",
      "('k', '0.0000162')\n",
      "('l', '0.0146273')\n",
      "('m', '0.0009110')\n",
      "('n', '0.0011051')\n",
      "('o', '0.0913053')\n",
      "('p', '0.0000809')\n",
      "('q', '0.0000027')\n",
      "('r', '0.0310281')\n",
      "('s', '0.0245378')\n",
      "('t', '0.0171177')\n",
      "('u', '0.0185732')\n",
      "('v', '0.0000027')\n",
      "('w', '0.0078702')\n",
      "('x', '0.0000000')\n",
      "('y', '0.0121422')\n",
      "('z', '0.0002776')\n",
      "('.', '0.2449470')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'t'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['t']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "For the Markov(1) model, $p( x_1,x_2,...,x_N | x_0 ) = p(x_1|x_0)p(x_2|x_1) ... p(x_n|x_{n-1})$\n",
    "\n",
    "We can utilize numpy.random.choice function to generate variates from discrete distributions.\n",
    "\n",
    "(Probability vectors are normalized to sum up 1 in this example since they have precisional errors causing sums of 1.00001 or 0.99999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n",
      "cy\n",
      "ing\n",
      ".oro\n",
      "che.y\n",
      "vyst.t\n",
      "h.is.st\n",
      "ben.baca\n",
      "haror.whe\n",
      "thedelin.c\n",
      "wadat.bry.a\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tempMatrix= np.asarray(T)\n",
    "probMatrix= np.zeros(shape=(27,27))\n",
    "for letter in alphabet:\n",
    "    probMatrix[letter2idx[letter]] = (tempMatrix[letter2idx[letter]].astype(np.float))/(sum(tempMatrix[letter2idx[letter]].astype(np.float)))\n",
    "    \n",
    "\n",
    "\n",
    "#probMatrix[letter2idx['q']]   #-> vector of probabilities, Pr(X_(i+1)|X_i='q')\n",
    "#print np.sum(probMatrix[letter2idx['a']])\n",
    "#needed to normalize so they sum up to 1. Some of them are 1.0001 or 0.9999\n",
    "def guessNextLetter(previousLetter):\n",
    "    return np.random.choice(alphabet,p= probMatrix[letter2idx[previousLetter]])\n",
    "print guessNextLetter('t')    \n",
    "   \n",
    "def genRandomString(N):\n",
    "    randomString = '.'\n",
    "    randomString+= guessNextLetter(randomString[-1])\n",
    "    for i in range(1,N):\n",
    "        randomString+= guessNextLetter(randomString[-1])\n",
    "    return randomString\n",
    "#generates 10 random strings\n",
    "for i in range(2,12):\n",
    "    print(genRandomString(i)[1:])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried to come up with a solution where predicted values are not independent, so that consecutive letters such as th will be finely tuned. Could not implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
