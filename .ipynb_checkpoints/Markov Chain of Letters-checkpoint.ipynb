{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Åžirag Erkol\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to 16.3-5 and 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of $y_t$ mostly stays constant. However, sometimes it makes a change in its level (state) and continues there, and sometimes it changes its level for a t of length 1, and then changes back to its previous level. So, one random change should be in the state ($S_t$), and another in the observation ($y_t$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r_1, r_2 \\in U[0,30]$$\n",
    "$$S_t, y_t \\in [0,30]$$\n",
    "\\begin{array}{|c|c|c|} \\hline\n",
    "& S_{t-1}\\\\ \\hline\n",
    "S_t=S_{t-1} & p\\\\ \\hline\n",
    "S_t=r_1 & 1-p \\\\ \\hline\n",
    "\\end{array}\n",
    "\n",
    "\\begin{array}{|c|c|c|} \\hline\n",
    "& S_t\\\\ \\hline\n",
    "y_t=S_t & q\\\\ \\hline\n",
    "y_t=r_2 & 1-q \\\\ \\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"images/16.3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state (when it is not equal to $e$) either constantly increases one-by-one or drops to $a$. When the state equals to $e$, it either stays there or falls back to $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S_t, x_t \\in \\{a,b,c,d,e\\}$$\n",
    "\\begin{array}{|c|c|c|c|} \\hline\n",
    "& S_{t-1}(\\neq e) & S_{t-1}=e\\\\ \\hline\n",
    "S_t=S_{t-1}+1 & p & 0\\\\ \\hline\n",
    "S_t=a & 1-p & q\\\\ \\hline\n",
    "S_t=e & 0 & 1-q\\\\ \\hline\n",
    "\\end{array}\n",
    "$$x_t=S_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"images/16.4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a pattern in the observations, such that both 0 and 1 appear either three or four times consecutively. So, the state at a given time depends on the states of previous four times steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$i, j \\in \\{0,1\\}$$\n",
    "\\begin{array}{|c|c|c|c|} \\hline\n",
    "& S_{t-1}=S_{t-2}=S_{t-3}=S_{t-4}=i & S_{t-1}=S_{t-2}=S_{t-3}=i,\\ S_{t-4}=j & o/w\\ when\\ S_{t-1}=i\\\\ \\hline\n",
    "S_t=i & 0 & p & 1\\\\ \\hline\n",
    "S_t=j & 1 & 1-p & 0\\\\ \\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"images/16.5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed Graphical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"images/18.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.2_factor.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undirected Graphical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.2_undirected.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factorisation given was as follows: $$p(F|T,L)p(M)p(T|A)p(B|M)p(X|F)p(L|M)p(D|F,B)p(A)\\\\$$\n",
    "The minimal parametrisation required for the first factor is $N^2(N-1)$, since all $N$ states for T and L should be known along with $N-1$ states for F. Similarly, the second will have a parametrisation of $(N-1)$, third $N(N-1)$, fourth $N(N-1)$, fifth $N(N-1)$, sixth $N(N-1)$, seventh $N^2(N-1)$, and finally eighth $(N-1)$. Overall, this makes a minimal parametrisation of $2(N+1)^2(N-1)$ in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement is true. In the first graph, the head-to-head arrows on node F block the path. In the second, the head-to-head arrows at node D block the path. There is no other path between A and M. So, A and M are d-separated, thus they are conditionally independent when the given set is empty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_a1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_a2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement is false. When only X is given, the path is not blocked in the first graph, so the road is open. At T, arrows are head-to-tail but T is not given, so it does not block the path. At F, the arrows are head-to-head, but one of its descendants (X) is in the given subset, so F does not block the path neither. Finally, at L, the arrows are head-to-tail, but L is not in the given subset, so it also does not block the path. <br> \n",
    "We do not have to check the second one, but we still will. In the second, the head-to-head arrows at D block the path (since D is not in the given subset). <br>\n",
    "Since there is a path between A and M when X is given (first graph), we can say they are not d-separated. So, A and M are conditionally dependent given X. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_b1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_b2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement is false. In the first graph, the arrows at F are head-to-head, but the descendant X of F is in the guven subset, so F does not block the path. <br>\n",
    "Checking the second graph (which is not necessary since we already know there is a path between T and L when X is given), it can be seen that the head-to-head arrows at node D blocks the path. <br>\n",
    "Since there is a path between T and L when X is given, it can be said that they are not d-separated. Thus, T and L are conditionally dependent when X is given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_c1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_c2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement is true. In the first graph, at node F the arrows are head-to-tail, and since F is in the given subset, it blocks the path. In the second graph, the arrows at node F are tail-to-tail, and since F is given, once again it blocks the path. D also blocks, since the arrows are head-to-head and D is not in the given subset. Since all paths between X and L are blocked when F is given, they are d-separated. This means X and L are conditionally independent given F. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_d1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_d2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement is false. In the first graph, the only node in between is F, where the arrows are head-to-tail. Since, F is not in the given subset, it does not block the path.<br>\n",
    "Checking the second graph (which is not necessary), F does not block the path since the arrows are tail-to-tail and F is not in the given subset. The same applies for M. At B, the arrows are head-to-tail and B is not in the given subset, so B also does not block the path. Finally, at D, the arrows are head-to-head, but D is in the given subset, so it does not block the path. This means this path is also open.<br>\n",
    "Overall, since there are paths between X and L given D, it can be said that they are not d-separated, meanind X and L are conditionally dependent given D. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_e1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/18.4_e2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr?gr?mm?ng?H?m?w?rk 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', '0.0002835')\n",
      "('b', '0.0228302')\n",
      "('c', '0.0369041')\n",
      "('d', '0.0426290')\n",
      "('e', '0.0012216')\n",
      "('f', '0.0075739')\n",
      "('g', '0.0171385')\n",
      "('h', '0.0014659')\n",
      "('i', '0.0372661')\n",
      "('j', '0.0002353')\n",
      "('k', '0.0110124')\n",
      "('l', '0.0778259')\n",
      "('m', '0.0260757')\n",
      "('n', '0.2145354')\n",
      "('o', '0.0005459')\n",
      "('p', '0.0195213')\n",
      "('q', '0.0001749')\n",
      "('r', '0.1104770')\n",
      "('s', '0.0934290')\n",
      "('t', '0.1317960')\n",
      "('u', '0.0098029')\n",
      "('v', '0.0306574')\n",
      "('w', '0.0088799')\n",
      "('x', '0.0009562')\n",
      "('y', '0.0233701')\n",
      "('z', '0.0018701')\n",
      "('.', '0.0715219')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(T)):\n",
    "    T[i]=list(map(float,T[i]))\n",
    "for i in range(len(T)):\n",
    "    T[i]=T[i]/np.sum(T[i])\n",
    "T=np.vstack(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f1(N):\n",
    "    text='.'\n",
    "    ind=alphabet.index(text[0])\n",
    "    matrix1=T\n",
    "    for i in range(N):\n",
    "        for k in range(i):\n",
    "            matrix1=np.dot(matrix1,T)\n",
    "        letter=np.random.choice(alphabet,1,p=matrix1[ind])\n",
    "        text=text+letter.tostring()\n",
    "    print text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".o.slnro..l.edeoa..aeid.i.r...noyhnrarmyh.rewramt.a.i.r.rshru.ut.htnkllhsm.temiy..sgf.oyrtovqnibic.e\n"
     ]
    }
   ],
   "source": [
    "f1(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the probability values, we first need to check for the conditional dependencies. Assume we have a string $'a__df_c'$. Let's first number the empty letters: 'a23df6c'. Since we are using a Markov(1) model, it can be said that the empty letters are only dependent on the given last previous letter and the first next letter. In the case of empty cell 2, these letters are 'a' and 'd'. Then, the probability distribution turns out to be as following:\n",
    "$$p(2|1,4)=\\frac{p(1,2,4)}{p(1,4)}=\\frac{p(4|2) \\times p(2|1) \\times p(1)}{p(4|1) \\times p(1)}=\\frac{p(4|2) \\times p(2|1)}{p(4|1)}=\\frac{p(4='d'|2) \\times p(2|1='a')}{p(4='d'|1='a')}$$<br>\n",
    "This calculation will give the necessary probability distribution for the second cell, when the cell 1 and 4 are given. The following two parts are done using these calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f2(text):\n",
    "    text='.'+text\n",
    "    textnew=''\n",
    "    lastLetter=9999\n",
    "    if text[len(text)-1]==\"_\":\n",
    "        for i in range(len(text)):\n",
    "            if text[i]!=\"_\":\n",
    "                lastLetter=i\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == '_' :\n",
    "            matrix1=T\n",
    "            matrix2=T\n",
    "            matrix3=T\n",
    "            if i > lastLetter:\n",
    "                if i - lastLetter > 1:\n",
    "                    for k in range(i - lastLetter - 1):\n",
    "                        matrix1=np.dot(matrix1,T)\n",
    "                prob=matrix1[alphabet.index(text[lastLetter])]\n",
    "            else:\n",
    "                for j in range(len(text)):\n",
    "                    if j > i and text[j]!='_':\n",
    "                        ind2=j\n",
    "                        break\n",
    "                if i - ind1 > 1:\n",
    "                    for k in range(i - ind1 - 1):\n",
    "                        matrix1=np.dot(matrix1,T)\n",
    "                if ind2 - i > 1:\n",
    "                    for k in range(ind2 - i - 1):\n",
    "                        matrix2=np.dot(matrix2,T)\n",
    "                for k in range(ind2 - ind1 - 1):\n",
    "                    matrix3=np.dot(matrix3,T)\n",
    "                prob=np.multiply(matrix1[alphabet.index(text[ind1])],matrix2[:,alphabet.index(text[ind2])])/matrix3[alphabet.index(text[ind1]),alphabet.index(text[ind2])]\n",
    "            letter=np.random.choice(alphabet,1,p=prob)\n",
    "            textnew=textnew+letter.tostring()\n",
    "        else:\n",
    "            textnew=textnew+text[i]\n",
    "            ind1=i\n",
    "            continue\n",
    "    return textnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 1 - Sample 0: .the.br.un.fex.\n",
      "Word 1 - Sample 1: .theobrten.fex.\n",
      "Word 1 - Sample 2: .the.brdin.fex.\n",
      "Word 1 - Sample 3: .the.br.an.fex.\n",
      "Word 1 - Sample 4: .tha.brwon.fex.\n",
      "Word 1 - Sample 5: .theabrein.fix.\n",
      "Word 1 - Sample 6: .thdubrden.fex.\n",
      "Word 1 - Sample 7: .th..brean.fix.\n",
      "Word 1 - Sample 8: .the.brtin.fex.\n",
      "Word 1 - Sample 9: .th.obrton.fex.\n",
      "\n",
      "Word 2 - Sample 0: .oursthond.to.be.onsworyf\n",
      "Word 2 - Sample 1: .autsthenn.tobbe.onswaron\n",
      "Word 2 - Sample 2: .tuesthand.tombe.answeros\n",
      "Word 2 - Sample 3: .ourstheno.to.be.inswire.\n",
      "Word 2 - Sample 4: .bussthand.tombe.inswiri.\n",
      "Word 2 - Sample 5: .sussthind.toube.wnswere.\n",
      "Word 2 - Sample 6: .ouest..nd.tosbe.insworet\n",
      "Word 2 - Sample 7: .ousstoong.torbe.answer..\n",
      "Word 2 - Sample 8: .ouisthind.to.be.inswerit\n",
      "Word 2 - Sample 9: .butst.ang.toube..nswore.\n",
      "\n",
      "Word 3 - Sample 0: .inuath.hathane.te.rting\n",
      "Word 3 - Sample 1: .isiats.pathiny.tefrding\n",
      "Word 3 - Sample 2: .is.ate.wathane.dedr.ing\n",
      "Word 3 - Sample 3: .ichat..rathene.teer.ing\n",
      "Word 3 - Sample 4: .iv.ate.cawhing.beproing\n",
      "Word 3 - Sample 5: .intath.paphind.feersing\n",
      "Word 3 - Sample 6: .iteat..tathend.peer.ing\n",
      "Word 3 - Sample 7: .ig.ath.tathund.beer.ing\n",
      "Word 3 - Sample 8: .iv.ath.hatheng.ve.rting\n",
      "Word 3 - Sample 9: .ithath.washend.metr.ing\n",
      "\n",
      "Word 4 - Sample 0: .qunet.berz.tttl.t.pi.ioy.n..\n",
      "Word 4 - Sample 1: .qucut.marz.c.mnot.fr.toh.at.\n",
      "Word 4 - Sample 2: .qullt.h.iz.dunert.dn.mo..oo.\n",
      "Word 4 - Sample 3: .qur.t.eraz.t.xcit.tn.cts.te.\n",
      "Word 4 - Sample 4: .qur.t.terz.l..m.t.re.ass.pe.\n",
      "Word 4 - Sample 5: .qurit.w.nz.gieeit.pa.dld.ae.\n",
      "Word 4 - Sample 6: .queit.asaz.wiss.t.ie.ars.fs.\n",
      "Word 4 - Sample 7: .qu..t.i.az.amos.t.dd.inn.ts.\n",
      "Word 4 - Sample 8: .qur.t.tmrz..aiwut.u..moy.sf.\n",
      "Word 4 - Sample 9: .qul.t.huaz.rialrt.hs.ord.gf.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in test_strings:\n",
    "    for i in range(10):\n",
    "        print \"Word \" + str(test_strings.index(word) + 1) + \" - Sample \" + str(i) + \": \" + f2(word)\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f3(text):\n",
    "    text='.'+text\n",
    "    textnew=''\n",
    "    lastLetter=9999\n",
    "    totalProb=1\n",
    "    if text[len(text)-1]==\"_\":\n",
    "        for i in range(len(text)):\n",
    "            if text[i]!=\"_\":\n",
    "                lastLetter=i\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == '_' :\n",
    "            matrix1=T\n",
    "            matrix2=T\n",
    "            matrix3=T\n",
    "            if i > lastLetter:\n",
    "                if i - lastLetter > 1:\n",
    "                    for k in range(i - lastLetter - 1):\n",
    "                        matrix1=np.dot(matrix1,T)\n",
    "                prob=matrix1[alphabet.index(text[lastLetter])]\n",
    "            else:\n",
    "                for j in range(len(text)):\n",
    "                    if j > i and text[j]!='_':\n",
    "                        ind2=j\n",
    "                        break\n",
    "                if i - ind1 > 1:\n",
    "                    for k in range(i - ind1 - 1):\n",
    "                        matrix1=np.dot(matrix1,T)\n",
    "                if ind2 - i > 1:\n",
    "                    for k in range(ind2 - i - 1):\n",
    "                        matrix2=np.dot(matrix2,T)\n",
    "                for k in range(ind2 - ind1 - 1):\n",
    "                    matrix3=np.dot(matrix3,T)\n",
    "                prob=np.multiply(matrix1[alphabet.index(text[ind1])],matrix2[:,alphabet.index(text[ind2])])/matrix3[alphabet.index(text[ind1]),alphabet.index(text[ind2])]\n",
    "            totalProb=totalProb*max(prob)\n",
    "            letter=alphabet[int(np.where(prob==max(prob))[0])]\n",
    "            textnew=textnew+letter\n",
    "        else:\n",
    "            textnew=textnew+text[i]\n",
    "            ind1=i\n",
    "    return textnew, totalProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 1: .the.br.an.fex.\n",
      "log-probability: -3.5838206068\n",
      "\n",
      "Word 2: .oursthand.to.be.answere.\n",
      "log-probability: -11.4410973481\n",
      "\n",
      "Word 3: .in.ath.wathend.he.r.ing\n",
      "log-probability: -11.8189779975\n",
      "\n",
      "Word 4: .qur.t.terz.t....t.ae.t.e.ae.\n",
      "log-probability: -27.5276806691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in test_strings:\n",
    "    print \"Word \" + str(test_strings.index(word) + 1) + \": \" + str(f3(word)[0])\n",
    "    print \"log-probability:\", np.log(f3(word)[1])\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To improve the model for a better performance, we can use Markov(i) where i is greater than 1, such as Markov(4). This is because the probability of letters do not depend only on the previous letter, they can also depend on the ones before those or the ones coming after itself. So, a higher Markov model would give better performances, although the complexity would also be higher."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
